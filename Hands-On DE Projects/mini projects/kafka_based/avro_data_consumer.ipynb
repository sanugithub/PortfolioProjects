{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c67933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully consumed record with key 2 and value {'ID': 2, 'name': 'Product 2', 'category': 'category b', 'price': 12.989999771118164, 'last_updated': datetime.datetime(2023, 7, 8, 16, 10, 36, tzinfo=datetime.timezone.utc)}\n",
      "json_string data is added to the JSON file.\n",
      "Successfully consumed record with key 5 and value {'ID': 5, 'name': 'Product 5', 'category': 'category a', 'price': 6.49, 'last_updated': datetime.datetime(2023, 7, 8, 16, 13, 21, tzinfo=datetime.timezone.utc)}\n",
      "json_string data is added to the JSON file.\n",
      "Successfully consumed record with key 7 and value {'ID': 7, 'name': 'Product 7', 'category': 'category c', 'price': 15.989999771118164, 'last_updated': datetime.datetime(2023, 7, 8, 16, 13, 50, tzinfo=datetime.timezone.utc)}\n",
      "json_string data is added to the JSON file.\n",
      "Successfully consumed record with key 13 and value {'ID': 13, 'name': 'Product 13', 'category': 'category a', 'price': 5.49, 'last_updated': datetime.datetime(2023, 7, 10, 10, 25, 1, tzinfo=datetime.timezone.utc)}\n",
      "json_string data is added to the JSON file.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from confluent_kafka import DeserializingConsumer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroDeserializer\n",
    "from confluent_kafka.serialization import StringDeserializer\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Define Kafka configuration\n",
    "kafka_config = {\n",
    "    'bootstrap.servers': 'pkc-l7q2j.europe-north1.gcp.confluent.cloud:9092',\n",
    "    'sasl.mechanisms': 'PLAIN',\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.username': 'ITP23LS5O3ED63E2',\n",
    "    'sasl.password': 'tUvjdsCbOW4z85Rrd718EeVTJFJFu6TcxJpkEb9b6Nd6pqCzwHrm7GIgfsoH+hJp',\n",
    "    'group.id': 'group31',\n",
    "    'auto.offset.reset': 'latest'\n",
    "}\n",
    "\n",
    "# Create a Schema Registry client\n",
    "schema_registry_client = SchemaRegistryClient({\n",
    "  'url': 'https://psrc-y5q2k.europe-west3.gcp.confluent.cloud',\n",
    "  'basic.auth.user.info': '{}:{}'.format('3IRJ76LCLZNXFYO4', 'GGvyEo0YfBsrvKuLHqnl/WC3CAcxQC0y1XzOE134x3xiuzzORKI/e1iXbjUKhxtj')\n",
    "})\n",
    "\n",
    "# Fetch the latest Avro schema for the value\n",
    "subject_name = 'product_updates-value'\n",
    "schema_str = schema_registry_client.get_latest_version(subject_name).schema.schema_str\n",
    "\n",
    "# Create Avro Deserializer for the value\n",
    "key_deserializer = StringDeserializer('utf_8')\n",
    "avro_deserializer = AvroDeserializer(schema_registry_client, schema_str)\n",
    "\n",
    "# Define the DeserializingConsumer\n",
    "consumer = DeserializingConsumer({\n",
    "    'bootstrap.servers': kafka_config['bootstrap.servers'],\n",
    "    'security.protocol': kafka_config['security.protocol'],\n",
    "    'sasl.mechanisms': kafka_config['sasl.mechanisms'],\n",
    "    'sasl.username': kafka_config['sasl.username'],\n",
    "    'sasl.password': kafka_config['sasl.password'],\n",
    "    'key.deserializer': key_deserializer,\n",
    "    'value.deserializer': avro_deserializer,\n",
    "    'group.id': kafka_config['group.id'],\n",
    "    'auto.offset.reset': kafka_config['auto.offset.reset'],\n",
    "    #'enable.auto.commit': True,\n",
    "    #'auto.commit.interval.ms': 5000 # Commit every 5000 ms, i.e., every 5 seconds\n",
    "})\n",
    "\n",
    "# To handle serialization of datetime objects,defining a custom encoder.\n",
    "def datetime_encoder(obj):\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "# Path to the separate JSON file for each consumer\n",
    "file_path = 'consumer1.json'  \n",
    "\n",
    "# Python function to load append the json string data into json file.\n",
    "def write_to_json_file(json_string, file_path):\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(json_string + '\\n')\n",
    "\n",
    "# Subscribe to the 'retail_data' topic\n",
    "consumer.subscribe(['product_updates'])\n",
    "\n",
    "# Continually read messages from Kafka\n",
    "try:\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            print('Consumer error: {}'.format(msg.error()))\n",
    "            continue\n",
    "        \n",
    "        #Change the category column to lowercase,in source it's in uppercase.\n",
    "        msg.value()['category'] = msg.value()['category'].lower() \n",
    "        \n",
    "        # updating the price to half if product belongs to 'category a'\n",
    "        if msg.value()['category'] == 'category a':\n",
    "            \n",
    "            msg.value()['price'] = msg.value()['price'] * 0.5\n",
    "            msg.value()['price'] = round(msg.value()['price'],2)\n",
    "            \n",
    "        print('Successfully consumed record with key {} and value {}'.format(msg.key(), msg.value()))\n",
    "        json_string = json.dumps(msg.value(), default=datetime_encoder)\n",
    "\n",
    "        def write_to_json_file(json_string, file_path):\n",
    "            with open(file_path, 'a') as file:\n",
    "                file.write(json_string + '\\n')\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.isfile(file_path):\n",
    "            # Create the file and write the initial data\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(json_string + '\\n')\n",
    "        else:\n",
    "            # Append the data to the existing file\n",
    "            write_to_json_file(json_string, file_path)\n",
    "            print(\"json_string data is added to the JSON file.\")\n",
    "        file.close()\n",
    "           \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fadffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94157df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
