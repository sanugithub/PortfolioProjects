{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b501d7a1-e86c-4c5a-8091-1846d5a11398",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------------+--------------------+----------------+-------------+---------------------+\n|order_num|tracking_num|pck_recieved_date|package_deliver_date|          status|      address|last_update_timestamp|\n+---------+------------+-----------------+--------------------+----------------+-------------+---------------------+\n|     1000|     TRK1000|       2023-01-01|          2023-01-06|        Returned|   456 Oak St|  2023-01-01 05:41:55|\n|     1001|     TRK1001|       2023-01-01|          2023-01-06|      In Transit|  789 Pine St|  2023-01-01 08:43:50|\n|     1002|     TRK1002|       2023-01-01|          2023-01-05|Out for Delivery|   123 Elm St|  2023-01-01 17:44:29|\n|     1003|     TRK1003|       2023-01-01|          2023-01-04|      In Transit|  789 Pine St|  2023-01-01 05:29:16|\n|     1004|     TRK1004|       2023-01-01|          2023-01-02|         Delayed| 202 Birch Rd|  2023-01-01 13:12:49|\n|     1005|     TRK1005|       2023-01-01|          2023-01-03|       Delivered|101 Maple Ave|  2023-01-01 23:42:57|\n|     1006|     TRK1006|       2023-01-01|          2023-01-02|        Returned|101 Maple Ave|  2023-01-01 09:37:34|\n|     1007|     TRK1007|       2023-01-01|          2023-01-02|       Delivered|   456 Oak St|  2023-01-01 22:46:09|\n|     1008|     TRK1008|       2023-01-01|          2023-01-03|      In Transit|   123 Elm St|  2023-01-01 16:14:44|\n|     1009|     TRK1009|       2023-01-01|          2023-01-05|         Delayed| 202 Birch Rd|  2023-01-01 00:42:25|\n|     1010|     TRK1010|       2023-01-01|          2023-01-04|      In Transit| 202 Birch Rd|  2023-01-01 05:07:32|\n|     1011|     TRK1011|       2023-01-01|          2023-01-03|         Delayed|101 Maple Ave|  2023-01-01 03:21:20|\n|     1012|     TRK1012|       2023-01-01|          2023-01-02|      In Transit|   456 Oak St|  2023-01-01 03:45:31|\n|     1013|     TRK1013|       2023-01-01|          2023-01-02|       Delivered|   456 Oak St|  2023-01-01 15:17:46|\n|     1014|     TRK1014|       2023-01-01|          2023-01-02|         Delayed|101 Maple Ave|  2023-01-01 03:22:30|\n|     1015|     TRK1015|       2023-01-01|          2023-01-04|       Delivered|  789 Pine St|  2023-01-01 04:05:34|\n|     1016|     TRK1016|       2023-01-01|          2023-01-03|      In Transit| 202 Birch Rd|  2023-01-01 04:03:44|\n|     1017|     TRK1017|       2023-01-01|          2023-01-05|        Returned| 202 Birch Rd|  2023-01-01 19:03:48|\n|     1018|     TRK1018|       2023-01-01|          2023-01-02|         Delayed|   123 Elm St|  2023-01-01 06:16:24|\n|     1019|     TRK1019|       2023-01-01|          2023-01-03|       Delivered|   456 Oak St|  2023-01-01 19:31:06|\n+---------+------------+-----------------+--------------------+----------------+-------------+---------------------+\n\nData read from staging table completed\nData upserted in target table\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import *\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Upsert into Target Delta Table\").getOrCreate()\n",
    "\n",
    "# Paths for the staging and target Delta tables\n",
    "staging_table_path = \"dbfs:/tmp/staging_order_tracking\"\n",
    "target_table_path = \"dbfs:/tmp/target_order_tracking\"\n",
    "\n",
    "# Read from the staging Delta table\n",
    "staging_df = spark.read.format(\"delta\").load(staging_table_path)\n",
    "staging_df.show()\n",
    "print(\"Data read from staging table completed\")\n",
    "\n",
    "# Check if the target Delta table exists, create it if not\n",
    "if not DeltaTable.isDeltaTable(spark, target_table_path):\n",
    "    staging_df.write.format(\"delta\").save(target_table_path)\n",
    "\n",
    "# Create DeltaTable object for the target table\n",
    "target_delta_table = DeltaTable.forPath(spark, target_table_path)\n",
    "\n",
    "# Perform upsert from staging to target table using tracking_num as key\n",
    "target_delta_table.alias(\"target\").merge(\n",
    "    staging_df.alias(\"staging\"),\n",
    "    \"target.tracking_num = staging.tracking_num\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "print(\"Data upserted in target table\")\n",
    "\n",
    "# Register the target table in the Hive Metastore (Optional)\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS hive_metastore.target\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS hive_metastore.target.target_order_tracking USING DELTA LOCATION '{target_table_path}'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "target_logistic_tracking_upsert_job",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
