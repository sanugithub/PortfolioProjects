#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import threading
from confluent_kafka import DeserializingConsumer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.schema_registry.avro import AvroDeserializer
from confluent_kafka.serialization import StringDeserializer
import os
from datetime import *

#################### cassandra db connect ######################
import uuid
from cassandra import ConsistencyLevel
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
import json

# This secure connect bundle is autogenerated when you download your SCB, 
# if yours is different update the file name below
cloud_config= {
  'secure_connect_bundle': 'secure-connect-ecommerce-db.zip'
}

# This token JSON file is autogenerated when you download your token, 
# if yours is different update the file name below
with open("ecommerce_db-token.json") as f:
    secrets = json.load(f)

CLIENT_ID = secrets["clientId"]
CLIENT_SECRET = secrets["secret"]

auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)
cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)
session = cluster.connect()

row = session.execute("select release_version from system.local").one()
if row:
  print(row[0])
else:
  print("An error occurred.")
#################### cassandra db connect ######################


# In[ ]:


# Define Kafka configuration
kafka_config = {
    'bootstrap.servers': 'pkc-l7pr2.ap-south-1.aws.confluent.cloud:9092',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': 'DSZRFJEEYC5DJRGR',
    'sasl.password': 'G2Ipwc64/MaBLAHyCO7r5ilzvwL1WfYGx8kmJYR6mW0IdFSC6SZS9ePJOteK+Wtr',
    'group.id': 'group14',
    'auto.offset.reset': 'earliest'
}


# In[ ]:


# Create a Schema Registry client
schema_registry_client = SchemaRegistryClient({
    'url': 'https://psrc-10dzz.ap-southeast-2.aws.confluent.cloud',
    'basic.auth.user.info': '{}:{}'.format('L5DYQTKB4BQ6PNOI', '5/+eLthGNYX3o61kbqm37EhIuqmjcSSnQZOE+FsOgQUh5zvOYkQ5mzNdSJYZ5Zsi')
})

# Fetch the latest Avro schema for the value
subject_name = 'ecommerce-orders-value'
schema_str = schema_registry_client.get_latest_version(subject_name).schema.schema_str

# Create Avro Deserializer for the value
key_deserializer = StringDeserializer('utf_8')
avro_deserializer = AvroDeserializer(schema_registry_client, schema_str)


# In[ ]:


#using ecommerce keyspace
ekeyspace = 'use ecommerce'
session.execute(ekeyspace)
print('Inside the ecommerce keyspace')


# In[ ]:


# Define the DeserializingConsumer
consumer = DeserializingConsumer({
    'bootstrap.servers': kafka_config['bootstrap.servers'],
    'security.protocol': kafka_config['security.protocol'],
    'sasl.mechanisms': kafka_config['sasl.mechanisms'],
    'sasl.username': kafka_config['sasl.username'],
    'sasl.password': kafka_config['sasl.password'],
    'key.deserializer': key_deserializer,
    'value.deserializer': avro_deserializer,
    'group.id': kafka_config['group.id'],
    'auto.offset.reset': kafka_config['auto.offset.reset']
})

# Subscribe to the 'ecommerce-orders' topic
consumer.subscribe(['ecommerce-orders'])


# In[ ]:

# consistency_level=ConsistencyLevel.QUORUM

# Process and insert Avro messages into Cassandra db
try:
    while True:
        msg = consumer.poll(1.0)  # Adjust the timeout as needed

        if msg is None:
            continue
        if msg.error():
            print('Order error: {}'.format(msg.error()))
            continue

        # Deserialize Avro data
        value = msg.value()
        print("Received message:", value)
        
        # Data validation checks
        if 'order_id' not in value or value['order_id'] is None:
            print("Skipping message due to missing or null 'order_id'.")
            continue

        if 'customer_id' not in value or value['customer_id'] is None:
            print("Skipping message due to missing or null 'customer_id'.")
            continue
        
        #We can add more checks as needed but this is just a demo
        
        # Check if a row with the same 'order_id' and 'customer_id' exists
        select_query = f"select count(*) as row_count from orders where order_id={value['order_id']} and customer_id={value['customer_id']}"
        result = session.execute(select_query)
        existing_record = result.one()

        if existing_record[0]>=1:
            print(f"Record with OrderId {value['order_id']} and CustomerId {value['customer_id']} already exists. Skipping insertion.")
        else:
            # order_id = uuid.UUID(value['order_id'])
            # customer_id = uuid.UUID(value['customer_id'])
            opt_to_datetime = None
            if value['order_purchase_timestamp'] is not None and value['order_purchase_timestamp']!='unknown value':
                opt_to_datetime = datetime.strptime(value['order_purchase_timestamp'], '%d-%m-%Y %H:%M')
            
            oaa_to_datetime = None
            if value['order_approved_at'] is not None and value['order_approved_at']!='unknown value':
                oaa_to_datetime = datetime.strptime(value['order_approved_at'], '%d-%m-%Y %H:%M')

            odcd_to_datetime = None
            if value['order_delivered_carrier_date'] is not None and value['order_delivered_carrier_date']!='unknown value':
                odcd_to_datetime = datetime.strptime(value['order_delivered_carrier_date'], '%d-%m-%Y %H:%M')

            odcud_to_datetime = None
            if value['order_delivered_customer_date'] is not None and value['order_delivered_customer_date']!='unknown value':
                odcud_to_datetime = datetime.strptime(value['order_delivered_customer_date'], '%d-%m-%Y %H:%M')

            oedd_to_datetime = None
            if value['order_estimated_delivery_date'] is not None and value['order_estimated_delivery_date']!='unknown value':
                oedd_to_datetime = datetime.strptime(value['order_estimated_delivery_date'], '%d-%m-%Y %H:%M')

            orderTime =  opt_to_datetime.time()
            orderHour = orderTime.hour
            orderDayOfWeek = opt_to_datetime.strftime('%A')
            # print(orderHour, orderDayOfWeek)
            # exit()

            # Insert transformed data into Cassandra db
            # Prepare the insert statement with dynamic values
            insert_query = session.prepare("INSERT INTO orders (order_id, customer_id, order_status, order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, order_estimated_delivery_date, OrderHour, OrderDayOfWeek) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)")

            # Bind the dynamic values to the prepared statement
            bound_statement = insert_query.bind((value['order_id'], value['customer_id'], value['order_status'], opt_to_datetime, oaa_to_datetime, odcd_to_datetime, odcud_to_datetime, oedd_to_datetime, orderHour, orderDayOfWeek))

            # Execute the insert statement with the specified consistency level
            bound_statement.consistency_level = ConsistencyLevel.QUORUM
            session.execute(bound_statement)

            print(f"Inserted message into Cassandra with OrderId {value['order_id']} and CustomerId {value['customer_id']}")


except KeyboardInterrupt:
    pass
finally:
    # Commit the offset to mark the message as processed
    consumer.commit()
    consumer.close()
    session.shutdown()
    #print('all okay')


# In[ ]:




